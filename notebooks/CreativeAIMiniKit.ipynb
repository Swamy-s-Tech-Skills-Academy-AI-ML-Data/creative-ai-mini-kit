{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "706dbf20",
   "metadata": {},
   "source": [
    "# Exploring OpenAI API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98a231e",
   "metadata": {},
   "source": [
    "## Task 1: Import Required Modules and Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcafee87",
   "metadata": {},
   "source": [
    "This section imports all the necessary libraries and modules that will be used throughout this notebook for interacting with OpenAI's API, data manipulation, file handling, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b693f6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "import tiktoken\n",
    "from pypdf import PdfReader\n",
    "from IPython.display import Image, Markdown, display\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dead61",
   "metadata": {},
   "source": [
    "## Task 2: Set Up API Key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82825016",
   "metadata": {},
   "source": [
    "This section initializes the OpenAI client using your API key stored as an environment variable. This client will be used for all interactions with OpenAI's models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee880dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0538ca94",
   "metadata": {},
   "source": [
    "## Task 2.1: Configure Pandas Display Options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71aed522",
   "metadata": {},
   "source": [
    "This section sets up display options for pandas DataFrames to ensure that content is shown properly without truncation, and defines a helper function to format DataFrames with improved styling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80252e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "\n",
    "def pp(df):\n",
    "    return display(df.style.set_properties(subset=['emails'], **{'text-align': 'left', 'white-space': 'pre-wrap', 'width': '900px'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9a9289",
   "metadata": {},
   "source": [
    "## Task 3: Define Folder Paths and Review Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd0b467",
   "metadata": {},
   "source": [
    "This section establishes folder paths for storing reviews and generated emails, and defines a list of example customer reviews that will be used for generating response emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aeab7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the 'reviews' folder\n",
    "reviews_folder = \"./reviews\"\n",
    "\n",
    "# Path to the 'emails' folder\n",
    "emails_folder = \"./emails\"\n",
    "\n",
    "# Path to the 'pdfs' folder\n",
    "pdfs_folder = \"./pdfs\"\n",
    "\n",
    "# Path to the 'pdfs_summary' folder\n",
    "pdfs_summary_folder = \"./pdfs_summary\"\n",
    "\n",
    "# List of reviews\n",
    "reviews = [\n",
    "    \"These hiking boots exceeded my expectations. Great ankle support and waterproofing that actually works when crossing streams. Perfect for day hikes and weekend backpacking trips.\",\n",
    "    \"The sci-fi trilogy by Marcus Chen kept me on the edge of my seat! Incredible world-building and character development throughout all three books. Really hoping they adapt this for a streaming series soon!\",\n",
    "    \"This coffee maker is remarkably quiet compared to my previous one. Brews quickly and maintains perfect temperature. Definitely recommend for any coffee enthusiast.\",\n",
    "    \"The jacket runs slightly large and the material is heavier than what I expected based on the description. Had to return it and size down. The quality seems good but it's not ideal for transitional weather as advertised.\",\n",
    "    \"Absolutely impressed with these noise-cancelling headphones. Crystal clear audio without distortion even at high volumes, and the battery lasts for days. Worth every penny.\",\n",
    "    \"Purchased this smart watch last month and I'm thoroughly impressed. The fitness tracking is accurate, and the sleep monitoring has been eye-opening. The band is comfortable for all-day wear, though the charging cable is a bit finicky. Overall, it's become an essential part of my daily routine and the battery easily lasts 3-4 days on a single charge.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db7f9b2",
   "metadata": {},
   "source": [
    "## Task 4: Create Review Files if Not Already Present"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c84e53",
   "metadata": {},
   "source": [
    "This section creates individual text files for each customer review, saving them to the reviews folder with proper error handling to ensure all files are created successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c316daaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the review files in the 'emails' folder with error handling\n",
    "for i, review in enumerate(reviews, start=1):\n",
    "    file_path = os.path.join(reviews_folder, f\"review{i}.txt\")\n",
    "    try:\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(review)\n",
    "        print(f\"✅ Successfully created: {file_path}\")\n",
    "    except OSError as e:\n",
    "        print(f\"❌ Error writing to {file_path}: {e}\")\n",
    "\n",
    "print(\n",
    "    f\"\\nAll review files have been created in the '{reviews_folder}' folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59935b04",
   "metadata": {},
   "source": [
    "## Task 5: Read Reviews from .txt Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f26d2a6",
   "metadata": {},
   "source": [
    "This section reads all the review files from the reviews folder, loads them into a pandas DataFrame for organized processing, and displays the data for verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b3bbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the folder exists before reading files\n",
    "if not os.path.exists(reviews_folder):\n",
    "    raise FileNotFoundError(\n",
    "        f\"The folder '{reviews_folder}' does not exist. Please create it and add review files.\")\n",
    "\n",
    "# Read all .txt files from the 'reviews' folder\n",
    "reviews = []\n",
    "for filename in sorted(os.listdir(reviews_folder)):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(reviews_folder, filename)\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            reviews.append(file.read().strip())\n",
    "\n",
    "# Load reviews into a DataFrame\n",
    "columns = ['reviews', 'emails']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "df['reviews'] = reviews\n",
    "\n",
    "# Display the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae932b46",
   "metadata": {},
   "source": [
    "## Task 6: Generate Emails for Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da25dbba",
   "metadata": {},
   "source": [
    "This section uses OpenAI's GPT model to generate professional customer service email responses to each review. The emails are tailored to thank customers for positive feedback and address concerns in a professional manner, then saved to individual text files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0493344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = [{\"role\": \"system\",\n",
    "         \"content\": \"You are a polite customer support representative.\"}]\n",
    "\n",
    "postfix = (\n",
    "    \"\\n\\nWrite a professional email responding to customer reviews.\\n\"\n",
    "    \"- Thank customers for positive feedback.\\n\"\n",
    "    \"- Acknowledge and address concerns professionally.\\n\"\n",
    "    \"- Encourage continued engagement with the brand.\\n\"\n",
    "    \"- Keep responses brief and highly professional.\\n\"\n",
    "    \"- Do not offer promotions, discounts, or recommend other products.\"\n",
    ")\n",
    "\n",
    "\n",
    "def getMail(review):\n",
    "    chat_history = chat.copy()\n",
    "    chat_history.append({\"role\": \"user\", \"content\": review+postfix})\n",
    "\n",
    "    reply = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-1106\",\n",
    "        messages=chat_history\n",
    "    )\n",
    "\n",
    "    return reply.choices[0].message.content\n",
    "\n",
    "\n",
    "# Ensure the folder exists\n",
    "if not os.path.exists(emails_folder):\n",
    "    os.makedirs(emails_folder)\n",
    "\n",
    "df['emails'] = df.apply(lambda x: getMail(x.reviews), axis=1)\n",
    "\n",
    "# Save emails to files\n",
    "for index, row in df.iterrows():\n",
    "    response = row['emails']\n",
    "\n",
    "    # A. Check if the response is OK\n",
    "    if response:\n",
    "        print(\"✅ Response received successfully.\")\n",
    "\n",
    "        # B. Save the content inside reviewx_email.txt\n",
    "        email_file_path = os.path.join(\n",
    "            emails_folder, f\"review{index+1}_email.txt\")\n",
    "        try:\n",
    "            with open(email_file_path, \"w\", encoding=\"utf-8\") as email_file:\n",
    "                email_file.write(response)\n",
    "            print(f\"✅ Email content saved to: {email_file_path}\")\n",
    "        except OSError as e:\n",
    "            print(f\"❌ Error saving email content to {email_file_path}: {e}\")\n",
    "    else:\n",
    "        print(\"❌ No response received from OpenAI.\")\n",
    "\n",
    "pp(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2caa08",
   "metadata": {},
   "source": [
    "## Task 7: Generate Python Code from Natural Language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5429730",
   "metadata": {},
   "source": [
    "This section allows you to generate Python code by providing natural language descriptions. It leverages OpenAI's GPT model to translate your instructions into functioning Python code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69ef544",
   "metadata": {},
   "source": [
    "### 7.1 Main Code Generation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6607173a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_python_code(description):\n",
    "    \"\"\"\n",
    "    Generate Python code from a natural language description\n",
    "    \n",
    "    Args:\n",
    "        description (str): Natural language description of the code functionality\n",
    "    \n",
    "    Returns:\n",
    "        str: Generated Python code\n",
    "    \"\"\"\n",
    "    system_prompt = \"\"\"You are an expert Python programmer. \n",
    "Your task is to generate clean, efficient, and well-commented Python code \n",
    "based on the user's description. Follow these guidelines:\n",
    "\n",
    "1. Use Pythonic code style and best practices\n",
    "2. Add helpful comments explaining complex logic\n",
    "3. Include docstrings for functions and classes\n",
    "4. Handle potential errors where appropriate\n",
    "5. Provide efficient solutions with appropriate data structures\n",
    "6. Only respond with valid Python code, no explanations outside of code comments\"\"\"\n",
    "    \n",
    "    chat_messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": f\"Generate Python code for: {description}\"}\n",
    "    ]\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-1106\",\n",
    "        messages=chat_messages\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6807f0b",
   "metadata": {},
   "source": [
    "### 7.2 Save Generated Code to File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b886e1",
   "metadata": {},
   "source": [
    "This section provides utilities for saving your generated code to Python files in the generatedcode/python folder with unique timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39344c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_code_to_file(code, filename=None):\n",
    "    \"\"\"\n",
    "    Save generated code to a Python file with a unique filename\n",
    "    \n",
    "    Args:\n",
    "        code (str): The Python code to save\n",
    "        filename (str, optional): Base filename for the Python file. If not provided,\n",
    "                                 a timestamp-based name will be generated\n",
    "    \n",
    "    Returns:\n",
    "        str: Path to the saved file or None if there was an error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create the generatedcode/python folder path\n",
    "        code_folder = \"./generatedcode/python\"\n",
    "        if not os.path.exists(code_folder):\n",
    "            os.makedirs(code_folder)\n",
    "        \n",
    "        # Generate a unique filename if none provided\n",
    "        if filename is None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename = f\"generated_code_{timestamp}.py\"\n",
    "        elif not filename.endswith(\".py\"):\n",
    "            filename = f\"{filename}.py\"\n",
    "        \n",
    "        file_path = os.path.join(code_folder, filename)\n",
    "        \n",
    "        # Add a header comment with generation timestamp\n",
    "        timestamp_comment = f\"# Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\"\n",
    "        final_code = timestamp_comment + code\n",
    "        \n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(final_code)\n",
    "            \n",
    "        print(f\"✅ Code successfully saved to: {file_path}\")\n",
    "        return file_path\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error saving code to file: {e}\")\n",
    "        return None\n",
    "\n",
    "# Examples of saving code with different filename options\n",
    "\n",
    "# 1. Save with automatic timestamp-based filename\n",
    "# saved_file_path = save_code_to_file(custom_generated_code)\n",
    "\n",
    "# 2. Save with a specific filename\n",
    "# saved_file_path = save_code_to_file(custom_generated_code, \"word_frequency_counter\")\n",
    "\n",
    "# 3. Save all example-generated code with descriptive filenames\n",
    "# Example of how to save all the code generated from the multiple problems section\n",
    "def save_multiple_code_examples():\n",
    "    \"\"\"Save all the example code problems with descriptive filenames\"\"\"\n",
    "    code_problems = {\n",
    "        \"fibonacci\": \"fibonacci sequence using recursion\",\n",
    "        \"prime_checker\": \"prime number checker using Sieve of Eratosthenes\",\n",
    "        \"binary_search\": \"binary search implementation\",\n",
    "        \"quick_sort\": \"quick sort algorithm\",\n",
    "        \"linked_list\": \"linked list with insert and delete operations\"\n",
    "    }\n",
    "    \n",
    "    print(\"Generating and saving multiple code examples...\")\n",
    "    saved_files = []\n",
    "    \n",
    "    for file_prefix, problem in code_problems.items():\n",
    "        print(f\"\\nGenerating code for: {problem}\")\n",
    "        # Create the prompt with the prefix\n",
    "        full_prompt = f\"Write Python code for finding the {problem}\"\n",
    "        \n",
    "        # Generate the code\n",
    "        chat_history = [{\"role\": \"system\", \"content\": \"You are a computer programmer.\"}]\n",
    "        chat_history.append({\"role\": \"user\", \"content\": full_prompt})\n",
    "        \n",
    "        reply = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo-1106\",\n",
    "            messages=chat_history\n",
    "        )\n",
    "        \n",
    "        code = reply.choices[0].message.content\n",
    "        \n",
    "        # Create a unique filename with the prefix and timestamp\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filename = f\"{file_prefix}_{timestamp}.py\"\n",
    "        \n",
    "        # Save the code\n",
    "        file_path = save_code_to_file(code, filename)\n",
    "        if file_path:\n",
    "            saved_files.append(file_path)\n",
    "    \n",
    "    print(f\"\\nSaved {len(saved_files)} code files to the generatedcode/python folder\")\n",
    "    return saved_files\n",
    "\n",
    "# Uncomment to save multiple code examples:\n",
    "# all_saved_files = save_multiple_code_examples()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b08573",
   "metadata": {},
   "source": [
    "### 7.3 Example Code Generation Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483d8603",
   "metadata": {},
   "source": [
    "Here are some example prompts you can use to generate Python code for various common programming tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e92f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Data Processing\n",
    "data_processing_prompt = \"\"\"Create a function that reads a CSV file containing sales data (columns: date, product_id, quantity, price), \n",
    "calculates the total revenue per product, and returns the top 5 products by revenue.\"\"\"\n",
    "\n",
    "# Example 2: Web Scraping\n",
    "web_scraping_prompt = \"\"\"Write a script using BeautifulSoup and requests to scrape a weather website for the 5-day forecast of a given city, \n",
    "and save the results to a JSON file.\"\"\"\n",
    "\n",
    "# Example 3: Algorithm Implementation\n",
    "algorithm_prompt = \"\"\"Implement a binary search tree class with methods for insertion, deletion, search, and in-order traversal.\"\"\"\n",
    "\n",
    "# Example 4: Data Visualization\n",
    "visualization_prompt = \"\"\"Create a function that takes a pandas DataFrame with columns 'year' and 'temperature', \n",
    "and generates a line plot showing temperature trends over time with proper labeling and styling.\"\"\"\n",
    "\n",
    "# Example 5: API Integration\n",
    "api_prompt = \"\"\"Write a script that uses the requests library to fetch and display the latest news headlines from a News API, \n",
    "with error handling and rate limiting.\"\"\"\n",
    "\n",
    "# List of example prompts\n",
    "example_prompts = [\n",
    "    data_processing_prompt,\n",
    "    web_scraping_prompt,\n",
    "    algorithm_prompt,\n",
    "    visualization_prompt,\n",
    "    api_prompt\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660693fe",
   "metadata": {},
   "source": [
    "### 7.4 Generate Code from Example Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0848e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select an example prompt (you can change the index to try different examples)\n",
    "selected_prompt_index = 0  # 0-based index for the example_prompts list\n",
    "selected_prompt = example_prompts[selected_prompt_index]\n",
    "\n",
    "print(f\"Selected prompt:\\n{selected_prompt}\\n\")\n",
    "print(\"Generating code...\\n\")\n",
    "\n",
    "# Generate code from the selected prompt\n",
    "generated_code = generate_python_code(selected_prompt)\n",
    "\n",
    "print(\"Generated Python Code:\")\n",
    "print(generated_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff21a0cb",
   "metadata": {},
   "source": [
    "### 7.5 Generate Custom Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd78a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your custom code generation prompt\n",
    "custom_prompt = \"\"\"Create a function that takes a text string and returns the most frequent words and their counts as a dictionary,\n",
    "ignoring common stop words like 'the', 'a', 'and', etc.\"\"\"  # Replace with your own description\n",
    "\n",
    "print(f\"Custom prompt:\\n{custom_prompt}\\n\")\n",
    "print(\"Generating code...\\n\")\n",
    "\n",
    "# Generate code from the custom prompt\n",
    "custom_generated_code = generate_python_code(custom_prompt)\n",
    "\n",
    "print(\"Generated Python Code:\")\n",
    "print(custom_generated_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e71b6ad",
   "metadata": {},
   "source": [
    "### 7.6 Generate Code for Multiple Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b7b5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of programming problems to solve\n",
    "problems = [\n",
    "    \"fibonacci sequence using recursion\",\n",
    "    \"prime number checker using Sieve of Eratosthenes\",\n",
    "    \"binary search implementation\",\n",
    "    \"quick sort algorithm\",\n",
    "    \"linked list with insert and delete operations\"\n",
    "]\n",
    "\n",
    "# Set up the system prompt for programming tasks\n",
    "chat = [{\"role\": \"system\", \"content\": \"You are a computer programmer.\"}]\n",
    "prefix = \"Write Python code for finding the \"\n",
    "\n",
    "# Generate and display code for each problem\n",
    "for problem in problems:\n",
    "    chat_history = chat.copy()\n",
    "    chat_history.append({\"role\":\"user\", \"content\":prefix+problem})\n",
    "\n",
    "    reply = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-1106\",\n",
    "        messages=chat_history\n",
    "    )\n",
    "\n",
    "    print(problem.upper())\n",
    "    display(Markdown(reply.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b95e9e2",
   "metadata": {},
   "source": [
    "### 7.7 Execute Generated Code (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caccc931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new cell and paste the generated code there to test it\n",
    "# Make sure to replace any input data with actual values for testing\n",
    "\n",
    "# Example execution cell:\n",
    "# (Uncomment and paste your generated code below)\n",
    "\n",
    "# <paste generated code here>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6684592",
   "metadata": {},
   "source": [
    "## Task 8: Summarize Text\n",
    "\n",
    "This section demonstrates how to analyze and process text from PDFs using OpenAI's tokenization. We download a research paper, extract text from it, and calculate the token count. This is useful for:\n",
    "\n",
    "1. Understanding token usage when working with the OpenAI API\n",
    "2. Processing and analyzing document text\n",
    "3. Preparing text data for summarization tasks\n",
    "\n",
    "The example uses the \"Attention is All You Need\" paper that introduced the Transformer architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3457077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(text, encoding_name):\n",
    "    \"\"\"\n",
    "    Count the number of tokens in a string using a specific encoding\n",
    "    \n",
    "    Args:\n",
    "        text (str): The text to count tokens in\n",
    "        encoding_name (str): The name of the encoding to use\n",
    "        \n",
    "    Returns:\n",
    "        int: The number of tokens in the text\n",
    "    \"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(text))\n",
    "    return num_tokens\n",
    "\n",
    "# Create pdfs folder if it doesn't exist\n",
    "if not os.path.exists(pdfs_folder):\n",
    "    os.makedirs(pdfs_folder)\n",
    "\n",
    "# URL for the \"Attention is All You Need\" paper\n",
    "url = \"https://arxiv.org/pdf/1706.03762.pdf\"\n",
    "pdf_path = os.path.join(pdfs_folder, \"attention_paper.pdf\")\n",
    "\n",
    "# Download the PDF if it doesn't exist\n",
    "if not os.path.exists(pdf_path):\n",
    "    print(f\"Downloading paper from {url}...\")\n",
    "    ppr_data = requests.get(url).content\n",
    "    \n",
    "    with open(pdf_path, 'wb') as handler:\n",
    "        handler.write(ppr_data)\n",
    "    print(f\"✅ PDF saved to: {pdf_path}\")\n",
    "else:\n",
    "    print(f\"Using existing PDF file: {pdf_path}\")\n",
    "\n",
    "# Read the PDF and extract text from the first 2 pages\n",
    "reader = PdfReader(pdf_path)\n",
    "text = \"\"\n",
    "for page in reader.pages[:2]:\n",
    "    text += page.extract_text() + \"\\n\"\n",
    "\n",
    "# Count and display the number of tokens in the extracted text\n",
    "token_count = num_tokens_from_string(text, 'cl100k_base')\n",
    "print(f\"The first two pages contain {token_count} tokens using the cl100k_base encoding.\")\n",
    "\n",
    "# Display a small preview of the extracted text\n",
    "preview_length = min(500, len(text))\n",
    "print(f\"\\nPreview of extracted text (first {preview_length} characters):\")\n",
    "print(\"-\" * 80)\n",
    "print(text[:preview_length] + \"...\")\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90510516",
   "metadata": {},
   "source": [
    "### 8.1 Text Summarization with OpenAI API\n",
    "\n",
    "Now that we have extracted text from the PDF and counted the tokens, let's use OpenAI's API to generate a concise summary of the text. This demonstrates how to process longer documents and extract key information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4aab58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text(text, max_tokens=4000):\n",
    "    \"\"\"\n",
    "    Summarize a long text using OpenAI's GPT model\n",
    "    \n",
    "    Args:\n",
    "        text (str): The text to summarize\n",
    "        max_tokens (int): Maximum tokens to process (to avoid token limits)\n",
    "    \n",
    "    Returns:\n",
    "        str: A concise summary of the text\n",
    "    \"\"\"\n",
    "    # Truncate text if it's too long\n",
    "    encoding = tiktoken.get_encoding('cl100k_base')\n",
    "    tokens = encoding.encode(text)\n",
    "    \n",
    "    if len(tokens) > max_tokens:\n",
    "        print(f\"⚠️ Text is too long ({len(tokens)} tokens). Truncating to {max_tokens} tokens.\")\n",
    "        truncated_tokens = tokens[:max_tokens]\n",
    "        text = encoding.decode(truncated_tokens)\n",
    "    \n",
    "    # Create system and user messages\n",
    "    system_message = \"\"\"You are an expert at summarizing academic and technical content.\n",
    "Your task is to create a concise yet comprehensive summary of the provided text.\n",
    "Focus on the main points, methodologies, and conclusions.\"\"\"\n",
    "    \n",
    "    user_message = f\"\"\"Please provide a clear summary of the following text from a research paper.\n",
    "Structure the summary with these sections:\n",
    "1. Main Topic and Purpose\n",
    "2. Key Concepts Introduced\n",
    "3. Methodology (if applicable)\n",
    "4. Main Findings or Contributions\n",
    "\n",
    "TEXT TO SUMMARIZE:\n",
    "{text}\"\"\"\n",
    "    \n",
    "    # Generate the summary\n",
    "    chat_messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_message}\n",
    "    ]\n",
    "    \n",
    "    print(\"Generating summary...\")\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-1106\",\n",
    "        messages=chat_messages\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Define the summaries folder path\n",
    "pdfs_summary_folder = \"./pdfs_summary\"\n",
    "\n",
    "# Create summary folder if it doesn't exist\n",
    "if not os.path.exists(pdfs_summary_folder):\n",
    "    os.makedirs(pdfs_summary_folder)\n",
    "    print(f\"✅ Created summaries folder: {pdfs_summary_folder}\")\n",
    "\n",
    "# Generate and display the summary\n",
    "summary = summarize_text(text)\n",
    "print(\"\\nSUMMARY OF THE PAPER:\\n\")\n",
    "display(Markdown(summary))\n",
    "\n",
    "# Save the summary to the pdfs_summary folder\n",
    "summary_path = os.path.join(pdfs_summary_folder, \"attention_paper_summary.txt\")\n",
    "with open(summary_path, \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(summary)\n",
    "print(f\"✅ Summary saved to: {summary_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
